{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e569d931",
   "metadata": {
    "tags": [
     "remove-input",
     "active-ipynb",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from openmdao.utils.notebook_utils import notebook_mode\n",
    "except ImportError:\n",
    "    !python -m pip install openmdao[notebooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e8af7",
   "metadata": {},
   "source": [
    "(sec:openmdao_math)=\n",
    "# Math Library (`openmdao.math`)\n",
    "\n",
    "Certain functions are useful in a gradient-based optimization context, such as smooth activation functions or differentiable maximum/minimum functions.\n",
    "\n",
    "Rather than provide a component that forces a user to structure their system in a certain way and add more components than necessary, the `openmdao.math` package is intended to provide a universal source for _composable_ functions that users can use within their own components.\n",
    "\n",
    "These functions trade accuracy for differentiability.\n",
    "Near regions where the nominal functions would have invalid derivatives, these functions are smooth but will not perfectly match their non-smooth counterparts.\n",
    "\n",
    "These functions can also be constructed using the `jax` library to support automatic differentiation and just-in-time compilation, as explained below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86efbe58",
   "metadata": {},
   "source": [
    "## Available Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a201b2ba",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    "    .. autofunction:: openmdao.math.act_tanh\n",
    "        :noindex:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fa1f1",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import openmdao.math as omm\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "fig.suptitle('Impact of different parameters on act_tanh')\n",
    "x = np.linspace(0, 1, 1000)\n",
    "\n",
    "mup001 = omm.act_tanh(x, mu=0.001, z=0.5, a=0, b=1)\n",
    "mup01 = omm.act_tanh(x, mu=0.01, z=0.5, a=0, b=1)\n",
    "mup1 = omm.act_tanh(x, mu=0.1, z=0.5, a=0, b=1)\n",
    "\n",
    "ax[0, 0].plot(x, mup001, label=r'$\\mu$ = 0.001')\n",
    "ax[0, 0].plot(x, mup01, label=r'$\\mu$ = 0.01')\n",
    "ax[0, 0].plot(x, mup1, label=r'$\\mu$ = 0.1')\n",
    "ax[0, 0].legend()\n",
    "ax[0, 0].grid()\n",
    "\n",
    "zp5 = omm.act_tanh(x, mu=0.01, z=0.5, a=0, b=1)\n",
    "zp4 = omm.act_tanh(x, mu=0.01, z=0.4, a=0, b=1)\n",
    "zp6 = omm.act_tanh(x, mu=0.01, z=0.6, a=0, b=1)\n",
    "\n",
    "ax[0, 1].plot(x, zp4, label=r'$z$ = 0.4')\n",
    "ax[0, 1].plot(x, zp5, label=r'$z$ = 0.5')\n",
    "ax[0, 1].plot(x, zp6, label=r'$z$ = 0.6')\n",
    "ax[0, 1].legend()\n",
    "ax[0, 1].grid()\n",
    "\n",
    "a0 = omm.act_tanh(x, mu=0.01, z=0.5, a=0, b=1)\n",
    "ap2 = omm.act_tanh(x, mu=0.01, z=0.5, a=0.2, b=1)\n",
    "ap4 = omm.act_tanh(x, mu=0.01, z=0.5, a=0.4, b=1)\n",
    "\n",
    "ax[1, 0].plot(x, a0, label=r'$a$ = 0.0')\n",
    "ax[1, 0].plot(x, ap2, label=r'$a$ = 0.2')\n",
    "ax[1, 0].plot(x, ap4, label=r'$a$ = 0.4')\n",
    "ax[1, 0].legend()\n",
    "ax[1, 0].grid()\n",
    "\n",
    "bp6 = omm.act_tanh(x, mu=0.01, z=0.5, a=0, b=.6)\n",
    "bp8 = omm.act_tanh(x, mu=0.01, z=0.5, a=0, b=.8)\n",
    "b1 = omm.act_tanh(x, mu=0.01, z=0.5, a=0, b=1)\n",
    "\n",
    "ax[1, 1].plot(x, bp6, label=r'$b$ = 0.6')\n",
    "ax[1, 1].plot(x, bp8, label=r'$b$ = 0.8')\n",
    "ax[1, 1].plot(x, b1, label=r'$b$ = 1.0')\n",
    "ax[1, 1].legend()\n",
    "ax[1, 1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b50cc",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    "    .. autofunction:: openmdao.math.smooth_abs\n",
    "        :noindex:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308f5047",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "fig.suptitle('Impact of different parameters on smooth_abs')\n",
    "x = np.linspace(-0.2, 0.2, 1000)\n",
    "\n",
    "mup001 = omm.smooth_abs(x, mu=0.001)\n",
    "mup01 = omm.smooth_abs(x, mu=0.01)\n",
    "mup1 = omm.smooth_abs(x, mu=0.1)\n",
    "\n",
    "ax.plot(x, mup001, label=r'$\\mu$ = 0.001')\n",
    "ax.plot(x, mup01, label=r'$\\mu$ = 0.01')\n",
    "ax.plot(x, mup1, label=r'$\\mu$ = 0.1')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268fc9f7",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    "    .. autofunction:: openmdao.math.smooth_max\n",
    "        :noindex:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cb8c2",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "fig.suptitle('Impact of different parameters on smooth_max of sin and cos')\n",
    "x = np.linspace(0.5, 1, 1000)\n",
    "\n",
    "sin = np.sin(x)\n",
    "cos = np.cos(x)\n",
    "\n",
    "mup001 = omm.smooth_max(sin, cos, mu=0.001)\n",
    "mup01 = omm.smooth_max(sin, cos, mu=0.01)\n",
    "mup1 = omm.smooth_max(sin, cos, mu=0.1)\n",
    "\n",
    "ax.plot(x, sin, '--', label=r'$\\sin{x}$')\n",
    "ax.plot(x, cos, '--', label=r'$\\cos{x}$')\n",
    "ax.plot(x, mup01, label=r'$\\mu$ = 0.01')\n",
    "ax.plot(x, mup1, label=r'$\\mu$ = 0.1')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b3f93a",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    "    .. autofunction:: openmdao.math.smooth_min\n",
    "        :noindex:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322fd31",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "fig.suptitle('Impact of different parameters on smooth_min of sin and cos')\n",
    "x = np.linspace(0.5, 1, 1000)\n",
    "\n",
    "sin = np.sin(x)\n",
    "cos = np.cos(x)\n",
    "\n",
    "mup001 = omm.smooth_min(sin, cos, mu=0.001)\n",
    "mup01 = omm.smooth_min(sin, cos, mu=0.01)\n",
    "mup1 = omm.smooth_min(sin, cos, mu=0.1)\n",
    "\n",
    "ax.plot(x, sin, '--', label=r'$\\sin{x}$')\n",
    "ax.plot(x, cos, '--', label=r'$\\cos{x}$')\n",
    "ax.plot(x, mup01, label=r'$\\mu$ = 0.01')\n",
    "ax.plot(x, mup1, label=r'$\\mu$ = 0.1')\n",
    "ax.legend(ncol=2)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed36a21",
   "metadata": {},
   "source": [
    "## Derivative functions\n",
    "\n",
    "The functions provided in `openmdao.math` have corresponing analytic derivative functions.\n",
    "\n",
    "These functions are vectorized in such a way that their jacobian matrix is typically diagonal, where the diagonal elements of the jacobian are nonzero and all off-diagonal elements are zero.\n",
    "Instead of returning the entire dense jacobian, these derivative functions generally return the diagonal elements only.\n",
    "There are some exceptions to this, such as `norm`, since it can return a non-diagonal jacobian when the `axis` argument is specified.\n",
    "\n",
    "Derivatives of function outputs with respect to their inputs are returned by functions named\n",
    "`d_{func_name}`. In addition to the arguments of the function, functions which accept more than one argument\n",
    "provide boolean arguments which determine whether the derivative with respect to each argument is returned.\n",
    "\n",
    "For instance, `d_smooth_abs(x, mu=1.0E-5, dmu=False)` returns the jacobian matrix for the smooth absolute value function with respect `x` and `None`, since the user disabled the calculation of the derivatives with respect to `mu`.  This can be useful when some arguments to the function are constants in the particular use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5f1891",
   "metadata": {},
   "source": [
    "```{eval-rst}\n",
    "    .. autofunction:: openmdao.math.d_act_tanh\n",
    "        :noindex:\n",
    "```\n",
    "\n",
    "```{eval-rst}\n",
    "    .. autofunction:: openmdao.math.d_smooth_abs\n",
    "        :noindex:\n",
    "```\n",
    "\n",
    "```{eval-rst}\n",
    "    .. autofunction:: openmdao.math.d_smooth_max\n",
    "        :noindex:\n",
    "```\n",
    "\n",
    "```{eval-rst}\n",
    "    .. autofunction:: openmdao.math.d_smooth_min\n",
    "        :noindex:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28484d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openmdao.math as omm\n",
    "\n",
    "x = np.linspace(-2, 2, 5)\n",
    "print(f'x = {x}\\n')\n",
    "\n",
    "d_sabs_dx, d_sabs_dmu = omm.d_smooth_abs(x, mu=1.0E-5, dmu=False)\n",
    "\n",
    "print(f'd_smoothabs_dx = {d_sabs_dx}\\n')\n",
    "print(f'd_smoothabs_dmu = {d_sabs_dmu}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1302976",
   "metadata": {},
   "source": [
    "## Example Use-Case - Differentiable Counting\n",
    "\n",
    "Suppose we have some array of data and we want a count of the number of elements in the array that are greater than or equal to some given value.\n",
    "\n",
    "We can use the `act_tanh` function and set it to return 0 for values less than our threshold, and 1 for valeus greater than our threshold.\n",
    "\n",
    "Summing the result of _this_ function will then give us the count.\n",
    "It will be approximate in that there is some inaccuracy where the activation function is smoothed, but it will be differentiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc845ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmdao.api as om\n",
    "from openmdao.math import act_tanh, d_act_tanh\n",
    "\n",
    "\n",
    "class CountingComp(om.ExplicitComponent):\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.options.declare('vec_size', types=(int,))\n",
    "        self.options.declare('threshold', types=(float,), default=0.0)\n",
    "        self.options.declare('mu', types=(float,), default=0.01)\n",
    "    \n",
    "    def setup(self):\n",
    "        n = self.options['vec_size']\n",
    "        self.add_input('x', shape=(n,))\n",
    "        self.add_output('count', shape=(1,))\n",
    "        \n",
    "        self.declare_partials(of='count', wrt='x')\n",
    "    \n",
    "    def compute(self, inputs, outputs):\n",
    "        z = self.options['threshold']\n",
    "        x = inputs['x']\n",
    "        mu = self.options['mu']\n",
    "        \n",
    "        outputs['count'] = np.sum(act_tanh(x, mu=mu, z=z, a=0, b=1))\n",
    "        \n",
    "    def compute_partials(self, inputs, partials):\n",
    "        z = self.options['threshold']\n",
    "        x = inputs['x']\n",
    "        mu = self.options['mu']\n",
    "        \n",
    "        dact_dx, _, _, _, _ = d_act_tanh(x, mu=mu, z=z, a=0, b=1,\n",
    "                                         dmu=False, dz=False, da=False, db=False)\n",
    "        # The derivative of the sum function is just a row of ones, so we can just do this.\n",
    "        partials['count', 'x'] = dact_dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d19c963",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "p = om.Problem()\n",
    "p.model.add_subsystem('counter',\n",
    "                      CountingComp(vec_size=N,threshold=0.5, mu=0.01),\n",
    "                      promotes_inputs=['x'], promotes_outputs=['count'])\n",
    "p.setup(force_alloc_complex=True)\n",
    "p.set_val('x', np.random.random(N))\n",
    "p.run_model()\n",
    "p.check_partials(method='cs', compact_print=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc4c80",
   "metadata": {},
   "source": [
    "# `jax` Math Library (openmdao.math.jax)\n",
    "\n",
    "The `jax` Python package provides functionality that duplicates the math capability of in `openmdao.math` but built upon the `jax` python packaage.\n",
    "This allows these functions to support automatic differentiation and just-in-time (jit) compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d12cd",
   "metadata": {},
   "source": [
    "## Getting derivatives from `jax`\n",
    "\n",
    "Now instead of using  the `d_smooth_abs` function, we have the option of using the automatic differentiation tools in `jax` to do the differentiation for us.  Useful methods from `jax` here are `grad`, which only supports scalar functions, `jacfwd` and `jacrev`, which provide a full, dense jacobian, and the `jvp` and `vjp` methods which can provide matrix-free derivatives that only include the diagonal elements we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import openmdao.math.jax as omj\n",
    "\n",
    "\n",
    "x = np.linspace(-1, 1, 100)\n",
    "\n",
    "act_x = omm.act_tanh(x, z=0, mu=1.0E-1, a=5, b=10)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(6, 10))\n",
    "\n",
    "ax[0].set_title('openmdao.math.jax.act_tanh(x, z=0, mu=0.1, a=5, b=10)')\n",
    "ax[0].plot(x, act_x)\n",
    "ax[0].grid()\n",
    "\n",
    "def d_act_tanh(x):\n",
    "    return jax.jacfwd(omj.act_tanh)(jax.numpy.ravel(x), z=0, mu=1.0E-1, a=5, b=10)\n",
    "\n",
    "ax[1].set_title('Jacobian matrix of openmdao.math.jax.act_tanh(x, z=0, mu=0.1, a=5, b=10)')\n",
    "ax[1].imshow(d_act_tanh(x), aspect='auto')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c26572",
   "metadata": {},
   "outputs": [],
   "source": [
    "We can change this to retrieve only the diagonal if we wish, since all off-diagonal elements are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8398a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0.01\n",
    "z = 0.5\n",
    "\n",
    "def d_act_tanh_jacfwd(x, z):\n",
    "    d_dx, d_dz = jax.jacfwd(omj.act_tanh, argnums=[0, 2])(jax.numpy.ravel(x), mu, z, a=5, b=10)\n",
    "    return jax.numpy.diagonal(d_dx), d_dz\n",
    "\n",
    "def d_act_tanh_jacrev(x, z):\n",
    "    d_dx, d_dz = jax.jacrev(omj.act_tanh, argnums=[0, 2])(jax.numpy.ravel(x), mu, z, a=5, b=10)\n",
    "    return jax.numpy.diagonal(d_dx), d_dz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd01ee6",
   "metadata": {},
   "source": [
    "## Performance of `jax` vs `numpy`\n",
    "\n",
    "Typically, automatically differentiated jax code is up to an order of magnitude slower in execution than providing analytic derivatives.\n",
    "\n",
    "We can improve the performance by using the just-in-time compiling capability of `jax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeb1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def d_act_tanh_jacfwd_jit(x, z):\n",
    "    d_dx, d_dz = jax.jacfwd(omj.act_tanh, argnums=[0, 2])(jax.numpy.ravel(x), mu, z, a=5, b=10)\n",
    "    return jax.numpy.diagonal(d_dx), d_dz\n",
    "\n",
    "@jax.jit\n",
    "def d_act_tanh_jacrev_jit(x, z):\n",
    "    d_dx, d_dz = jax.jacrev(omj.act_tanh, argnums=[0, 2])(jax.numpy.ravel(x), mu, z, a=5, b=10)\n",
    "    return jax.numpy.diagonal(d_dx), d_dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d495745",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "loop = 1000\n",
    "\n",
    "timing = {}\n",
    "timing['analytic'] = timeit.timeit('omm.d_act_tanh(x, mu, z, a=5, b=10, dx=True, dz=True)', globals=globals(), number=loop)\n",
    "timing['jacfwd'] = timeit.timeit('d_act_tanh_jacfwd(x, z)', globals=globals(), number=loop)\n",
    "timing['jacrev'] = timeit.timeit('d_act_tanh_jacrev(x, z)', globals=globals(), number=loop)\n",
    "timing['jacfwd_jit'] = timeit.timeit('d_act_tanh_jacfwd_jit(x, z)', globals=globals(), number=loop)\n",
    "timing['jacrev_jit'] = timeit.timeit('d_act_tanh_jacrev_jit(x, z)', globals=globals(), number=loop)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "fig.suptitle('Performance of analytic derivatives of act_tanh\\nvs jax with and without jit')\n",
    "ax.bar(timing.keys(), np.asarray(list(timing.values())) / loop, width = 0.4)\n",
    "ax.set_ylabel('Average time (s)')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39662387",
   "metadata": {},
   "source": [
    "Now the jax form of the functions are considerably faster than the numpy analytic derivative implementation.\n",
    "\n",
    "# Using the jax form of functions in components\n",
    "\n",
    "Building components with `jax` based functions is more easily accomplished by defining and jit-compiling those functions outside of the components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628b1a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmdao.api as om\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def _f_count(x, mu, z, a, b):\n",
    "    return np.sum(omj.act_tanh(x, mu=mu, z=z, a=0, b=1))\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def _d_f_count(x, mu, z, a, b):\n",
    "    return jax.jacfwd(_f_count, argnums=[0])(jax.numpy.ravel(x), mu, z, a, b)\n",
    "\n",
    "\n",
    "class CountingJaxComp(om.ExplicitComponent):\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.options.declare('vec_size', types=(int,))\n",
    "        self.options.declare('threshold', types=(float,), default=0.0)\n",
    "        self.options.declare('mu', types=(float,), default=0.01)\n",
    "    \n",
    "    def setup(self):\n",
    "        n = self.options['vec_size']\n",
    "        self.add_input('x', shape=(n,))\n",
    "        self.add_output('count', shape=(1,))\n",
    "        \n",
    "        self.declare_partials(of='count', wrt='x')\n",
    "    \n",
    "    def compute(self, inputs, outputs):\n",
    "        z = self.options['threshold']\n",
    "        x = inputs['x']\n",
    "        mu = self.options['mu']\n",
    "        \n",
    "        outputs['count'] = _f_count(x, mu, z, 0, 1)\n",
    "        \n",
    "    def compute_partials(self, inputs, partials):\n",
    "        z = self.options['threshold']\n",
    "        x = inputs['x']\n",
    "        mu = self.options['mu']\n",
    "        \n",
    "        partials['count', 'x'] = _d_f_count(x, mu, z, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47acf138",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10_000\n",
    "\n",
    "p = om.Problem()\n",
    "p.model.add_subsystem('counter',\n",
    "                      CountingJaxComp(vec_size=N,threshold=0.5, mu=0.01),\n",
    "                      promotes_inputs=['x'], promotes_outputs=['count'])\n",
    "p.setup(force_alloc_complex=True)\n",
    "p.set_val('x', np.random.random(N))\n",
    "p.run_model()\n",
    "p.check_partials(method='cs', compact_print=True);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
