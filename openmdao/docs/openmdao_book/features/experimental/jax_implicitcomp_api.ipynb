{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "active-ipynb",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from openmdao.utils.notebook_utils import notebook_mode  # noqa: F401\n",
    "except ImportError:\n",
    "    !python -m pip install openmdao[notebooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Partial Derivatives using JaxImplicitComponent\n",
    "\n",
    "One of the barriers to using OpenMDAO is that to truly take advantage of OpenMDAO, the user needs to write code for the analytic partial derivatives of their `Components`. To avoid that, users can use the optional third-party [JAX](https://jax.readthedocs.io/en/latest/index.html) library, which can automatically differentiate native Python and NumPy functions.  \n",
    "\n",
    "This notebook gives an example of using JAX to do automatic differentiation (AD) for a simple example.  Based on the sizes\n",
    "of inputs vs. outputs for a component, the `JaxImplicitComponent` will use either forward mode (for more outputs than inputs) or reverse mode (more inputs than outputs) to compute the partial jacobian. The choice of forward or reverse mode will be done automatically.  If a `JaxImplicitComponent`'s 'matrix_free' attribute is set, then the component will use the `jax.jvp` method in forward mode and `jax_vjp` in reverse mode.\n",
    "\n",
    "The `JaxImplicitComponent` will also use JAX's just-in-time (jit) compiling capabilities by default to dramatically speed up computations. jit can be disabled by setting self.options['use_jit'] to False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `jax` is not an OpenMDAO dependency that is installed by default, so you'll have to install it by ",
    "issuing one of the following commands at your operating system command prompt:\n",
    "```\n",
    "pip install jax jaxlib\n",
    "pip install openmdao[jax]\n",
    "pip install openmdao[all]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
        "remove-input",
        "active-ipynb",
        "remove-output"
       ]
   },
   "outputs": [],
   "source": [
    "!pip install jax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some standard OpenMDAO imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import openmdao.api as om"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The JAX library includes a NumPy-like API, `jax.numpy`, which implements the NumPy API using the primitives in JAX. Almost anything that can be done with NumPy can be done with `jax.numpy`. JAX arrays are similar to NumPy arrays, but they are designed to work with accelerators such as GPUs and TPUs. \n",
    "\n",
    "To use `jax.numpy`, it needs to be imported, using the commonly used `jnp` abbreviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax # noqa\n",
    "import jax.numpy as jnp  # noqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is one of the `JaxImplicitComponent`s in the model where derivatives will be computed using JAX. Comments interspersed in the code provide some explanations and guidance. Here is an overview of the steps that need to be taken to make use of JAX for your `JaxImplicitComponent`. \n",
    "\n",
    "1. Inherit your component from `JaxImplicitComponent`.\n",
    "\n",
    "2. Write a method named `compute_primal` to compute the residuals from the inputs and outputs. This method is the same as what you would normally write for the `apply_nonlinear` method of an `ImplicitComponent`, but it takes as its arguments the actual individual input and output variables rather than a dictionary of the inputs and outputs, and returns the residuals as a tuple. This allows us to use JAX's AD capabilities on this method. Ordering of the inputs and outputs is critical.  The order of the inputs and outputs passed into the method and the residuals returned from the method *must* match the order that they are declared in the component.  Also, discrete inputs, if any, are passed individually as arguments after the continuous variables.\n",
    "\n",
    "3. By default your component will jit the compute_primal method. If for some reason you don't want this, then\n",
    "you can set self.options['use_jit'] to False.\n",
    "\n",
    "4. For a typical component, that's it.  You can skip step 5.\n",
    "\n",
    "5. However, if your compute_primal depends on variables that are 'static', i.e., they don't change during computation of derivatives, you'll need to define a `get_self_statics` method on your component that returns a tuple containing all of the static variables that your compute_primal method depends on, excluding any discrete input variables.  The returned tuple must be hashable.  If these static values ever change, jax will recompile the `compute_primal` function.  In `LinSysComp` below, there is one static option variable, `self.options['adder']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinSysComp(om.JaxImplicitComponent):\n",
    "    def initialize(self):\n",
    "        self.options.declare('size', default=1, types=int)\n",
    "\n",
    "        # adder is a 'static' value that is constant during derivative computation, but it\n",
    "        # can be changed by the user between runs, so any jitted jax functions will be re-jitted\n",
    "        # if it changes\n",
    "        self.options.declare('adder', default=0., types=float)\n",
    "\n",
    "    def setup(self):\n",
    "        size = self.options['size']\n",
    "\n",
    "        shape = (size, )\n",
    "\n",
    "        self.add_input(\"A\", val=np.eye(size))\n",
    "        self.add_input(\"b\", val=np.ones(shape))\n",
    "        self.add_output(\"x\", shape=shape, val=.1)\n",
    "\n",
    "    def setup_partials(self):\n",
    "        size = self.options['size']\n",
    "        mat_size = size * size\n",
    "        full_size = size\n",
    "\n",
    "        row_col = np.arange(full_size, dtype=\"int\")\n",
    "        self.declare_partials('x', 'b', val=np.full(full_size, -1.0), rows=row_col, cols=row_col)\n",
    "\n",
    "        rows = np.repeat(np.arange(full_size), size)\n",
    "        cols = np.arange(mat_size)\n",
    "        self.declare_partials('x', 'A', rows=rows, cols=cols)\n",
    "\n",
    "        cols = np.tile(np.arange(size), size)\n",
    "        cols += np.repeat(np.arange(1), mat_size) * size\n",
    "        self.declare_partials(of='x', wrt='x', rows=rows, cols=cols)\n",
    "\n",
    "        # if we're runnning in matrix_free mode, we don't want to use a direct solver\n",
    "        if self.matrix_free:\n",
    "            self.linear_solver = om.ScipyKrylov()\n",
    "        else:\n",
    "            self.linear_solver = om.DirectSolver()\n",
    "        self.nonlinear_solver = om.NewtonSolver(solve_subsystems=False)\n",
    "\n",
    "    # we have a static variable, self.options['adder'] that we use in compute_primal, so we need to\n",
    "    # define theh get_self_statics method to tell OpenMDAO about it\n",
    "    def get_self_statics(self):\n",
    "        return (self.options['adder'], )\n",
    "\n",
    "    # compute_primal replaces the old apply_nonlinear method\n",
    "    def compute_primal(self, A, b, x):\n",
    "        return A.dot(x + self.options['adder']) - b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of this code is standard OpenMDAO code. The code can be run as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1., 1., 1.], [1., 2., 3.], [0., 1., 3.]])\n",
    "b = np.array([1, 2, -3])\n",
    "\n",
    "prob = om.Problem()\n",
    "\n",
    "ivc = prob.model.add_subsystem('ivc', om.IndepVarComp())\n",
    "ivc.add_output('A', A)\n",
    "ivc.add_output('b', b)\n",
    "\n",
    "lingrp = prob.model.add_subsystem('lingrp', om.Group())\n",
    "lin = lingrp.add_subsystem('lin', LinSysComp(size=b.size))\n",
    "\n",
    "prob.model.connect('ivc.A', 'lingrp.lin.A')\n",
    "prob.model.connect('ivc.b', 'lingrp.lin.b')\n",
    "\n",
    "prob.setup()\n",
    "prob.set_solver_print(level=0)\n",
    "\n",
    "prob.set_val('ivc.A', A)\n",
    "prob.set_val('ivc.b', b)\n",
    "\n",
    "prob.run_model()\n",
    "\n",
    "print(prob['lingrp.lin.x'])\n",
    "\n",
    "# changing the adder value should change the resulting x value\n",
    "lin.options['adder'] = 1.0\n",
    "\n",
    "prob.run_model()\n",
    "\n",
    "print(prob['lingrp.lin.x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from openmdao.utils.assert_utils import assert_near_equal, assert_check_totals, assert_check_partials\n",
    "\n",
    "assert_near_equal(prob['lingrp.lin.x'], np.array([-5, 8, -5]))\n",
    "\n",
    "assert_check_totals(prob.check_totals(of=['lingrp.lin.x'], wrt=['ivc.b', 'ivc.A'],\n",
    "                                      abs_err_tol=2e-4, rel_err_tol=3e-6, show_only_incorrect=True),\n",
    "                    atol=2e-4, rtol=3e-6)\n",
    "assert_check_partials(prob.check_partials(show_only_incorrect=True), rtol=1e-5)\n",
    "\n",
    "lin.options['adder'] = 0.0\n",
    "\n",
    "prob.run_model()\n",
    "\n",
    "assert_near_equal(prob['lingrp.lin.x'], np.array([-4, 9, -4]))\n",
    "\n",
    "assert_check_totals(prob.check_totals(of=['lingrp.lin.x'], wrt=['ivc.b', 'ivc.A'],\n",
    "                                        abs_err_tol=2e-4, rel_err_tol=3e-6, show_only_incorrect=True),\n",
    "                    atol=2e-4, rtol=3e-6)\n",
    "assert_check_partials(prob.check_partials(show_only_incorrect=True), rtol=1e-5)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orphan": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
